import torch
import torchvision
from dataset import MGDataset
from torch.utils.data import DataLoader
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
import json 
import pandas as pd
import os 
import random

def save_checkpoint(state, filename="my_checkpoint.pth.tar"):
    print("=> Saving Checkpoint")
    torch.save(state, filename)

def get_loaders(
    train_dir, 
    train_maskdir, 
    val_dir,
    val_maskdir,
    batch_size,
    train_transform,
    val_transform,
    num_workers=4,
    pin_memory=True
):
    train_ds = MGDataset(
        image_dir = train_dir,
        mask_dir = train_maskdir,
        transform = train_transform,
    )

    train_loader = DataLoader(
        train_ds,
        batch_size = batch_size,
        num_workers = num_workers,
        pin_memory = pin_memory,
        shuffle = True,
    )

    val_ds = MGDataset(
        image_dir = val_dir,
        mask_dir = val_maskdir,
        transform = val_transform,
    )

    val_loader = DataLoader(
        val_ds,
        batch_size=batch_size,
        num_workers=num_workers,
        pin_memory=pin_memory,
        shuffle=False,
    )

    return train_loader, val_loader

class MetricTracker():
    def __init__(self):
        self.precision = []
        self.accuracy = []
        self.recall = [] 
        self.dice = [] 
        self.loss = []

    def addMetrics(self, dice_score, tp, tn, fn, fp, loss = -1):
        self.dice.append(dice_score)
        self.accuracy.append((tp+tn)/(tp+tn+fp+fn))
        self.precision.append(tp/(tp+fp))
        self.recall.append(tp/(tp+fn))
        
        if loss == -1:
            # assume we using dice loss
            self.loss.append(1-dice_score)
        else: 
            self.loss.append(loss)

    def __str__(self):
        return f"dice: {self.dice}, accuracy: {self.accuracy}, precision: {self.precision}, recall: {self.recall}"


def check_accuracy(loader, model, train, metric_tracker : MetricTracker, loss_fn, device="cuda"):
    num_correct = 0
    num_pixels =0
    dice_score = 0
    loss = 0 
    model.eval()

    with torch.no_grad():
        for x, y in loader:
            x = x.to(device)
            y = y.to(device).unsqueeze(1)
            preds = torch.sigmoid(model(x))
            preds = (preds > 0.5).float()
            loss += float(loss_fn(preds, y).item())
            num_correct += (preds == y).sum()
            num_pixels += torch.numel(preds)
            y = y.cpu().numpy()
            preds = preds.cpu().numpy()
            dice_score += ((2.*(preds*y).sum())+1e-6)/(preds.sum()+y.sum()+1e-6)

    print(
        f"Got accuracy {num_correct/num_pixels}:.2f"
    )
    #f"Got accuracy {(tp + tn) / (tp + tn + fn + fp):.2f}"

    print(
        f"Dice Score {dice_score/len(loader)}         "
        f"Loss {loss/len(loader)}"
    )
    metric_tracker.addMetrics( dice_score/len(loader), 1, 1, 1, 1, loss=loss/len(loader))

    model.train()
    if train:
        return dice_score/len(loader), num_correct/num_pixels
        #return all_dices_train[-1], all_accuracies_train[-1]
    else: 
        return dice_score/len(loader), num_correct/num_pixels

# loss functions implemented from: https://www.kaggle.com/code/bigironsphere/loss-function-library-keras-pytorch
class DiceBCELoss(nn.Module):
    def __init__(self, weight=None, size_average=True):
        super(DiceBCELoss, self).__init__()

    def forward(self, inputs, targets, smooth=1e-6):
        
        # Binarise mask generated by model
        inputs_sig = F.sigmoid(inputs)       
        inputs_binary = (inputs_sig>0.5).float()
        
        #flatten label and prediction tensors
        inputs = inputs.view(-1)
        inputs_sig = inputs_sig.view(-1)
        inputs_binary = inputs_binary.view(-1)
        targets = targets.view(-1)
        
        # Calculation for the Dice_BCE loss.
        intersection = (inputs_binary * targets).sum()                            
        dice_loss = 1 - (2.*intersection + smooth)/(inputs_binary.sum() + targets.sum() + smooth)  
        BCE = F.binary_cross_entropy_with_logits(inputs, targets)
        Dice_BCE = BCE + dice_loss
        
        return Dice_BCE

class DiceLoss(nn.Module):
    def __init__(self, weight=None, size_average=True):
        super(DiceLoss, self).__init__()

    def forward(self, inputs, targets, smooth=1e-6):
        
        #comment out if your model contains a sigmoid or equivalent activation layer
        inputs = F.sigmoid(inputs)       
        inputs_binary = (inputs>0.5).float()
        
        #flatten label and prediction tensors
        inputs_binary = inputs.view(-1)
        targets = targets.view(-1)
        
        intersection = (inputs_binary * targets).sum()  

        dice = (2.*intersection + smooth)/(inputs_binary.sum() + targets.sum() + smooth)  
        return 1 - dice

class TverskyLoss(nn.Module):
    def __init__(self, alpha, beta, weight=None, size_average=True):
        super(TverskyLoss, self).__init__()
        self.alpha = alpha
        self.beta = beta

    def forward(self, inputs, targets, smooth=1e-6):
        
        #comment out if your model contains a sigmoid or equivalent activation layer
        inputs = F.sigmoid(inputs)       
        
        #flatten label and prediction tensors
        inputs = inputs.view(-1)
        targets = targets.view(-1)
        
        #True Positives, False Positives & False Negatives
        TP = (inputs * targets).sum()    
        FP = ((1-targets) * inputs).sum()
        FN = (targets * (1-inputs)).sum()
       
        Tversky = (TP + smooth) / (TP + self.alpha*FP + self.beta*FN + smooth)  
        
        return 1 - Tversky

# Adapted from: https://stackoverflow.com/questions/71998978/early-stopping-in-pytorch
class EarlyStopper:
    def __init__(self, patience=1, min_delta=0):
        self.patience = patience 
        self.min_delta = min_delta
        self.counter = 0

    def early_stop(self, validation_loss, training_loss, epoch):
        
        if epoch > 10:
            if abs(validation_loss - training_loss) >= self.min_delta or validation_loss > 0.98: 
                self.counter += 1
            else: 
                self.counter = 0 

        if self.counter >= self.patience:
            return True 
        return False

#https://stackoverflow.com/questions/60050586/pytorch-change-the-learning-rate-based-on-number-of-epochs
def adjust_learning_rate_in_training(optimizer, curr_epoch, iterations, s_lr, m_lr):
    lr = s_lr * (1 - (curr_epoch / iterations)) * (1 - (curr_epoch/iterations))
    if lr < m_lr:
        lr = m_lr

    for param_group in optimizer.param_groups:
        param_group['lr'] = lr

    return lr

def save_config_to_json(img_size, batch, s_lr, m_lr, iterations,train_metric:MetricTracker, valid_metric:MetricTracker, training_time, directory, notes, seed):
    """
        Dumps the configuration of the hyperparameters and the final metrics of dice, 
        accuracy, and training time into a json file. 
    """
    
    # Create dictionary with all hyper parameters and final metrics
    config = {}
    config["Image Size"] = img_size
    config["Batch Size"] = batch 
    config["Starting LR"] = s_lr 
    config["Minimum LR"] = m_lr
    config["Total Epochs"] = iterations
    config["Final Training Dice Score"] = train_metric.dice[-1]
    config["Final Training Accuracy"] = train_metric.accuracy[-1]
    config["Final Training Precision"] = train_metric.precision[-1]
    config["Final Training Recall"] = train_metric.recall[-1]
    config["Final Training Loss"] = train_metric.loss[-1]
    config["Final Validation Dice Score"] = valid_metric.dice[-1]  
    config["Final Validation Accuracy Score"] = valid_metric.accuracy[-1]
    config["Final Validation Precision"] = valid_metric.precision[-1]
    config["Final Validation Recall"] = valid_metric.recall[-1]
    config["Final Validation Loss"] = valid_metric.loss[-1] 
    config["Training Time"] = training_time
    config["Notes"] = notes
    config["Seed"] = seed

    # Dump dictionary into JSON file.
    with open(f"./{directory}/config.json", "w") as f:
        json.dump(config, f, indent=4)

def save_results_to_csv( directory : str, df : pd.DataFrame ):
    df.to_csv(f"./{directory}/metrics.csv", index=False)
    #accuracy_df.to_csv(f"./{directory}/accuracy.csv", index=False)
    
def set_seed(seed):
    np.random.seed(seed)
    random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed(seed)

    torch.backends.cudnn.deterministic = True 
    torch.backends.cudnn.benchmark = False
    os.environ["PYTHONHASHSEED"] = str(seed)


if __name__ == "__main__":
    # Test the dice loss function. Seems to be working well.

    
    square_middle = np.array(
        [0,0,0,0,0,1,1,0,0,1,1,0,0,0,0,0],
    )

    overlap_50 = np.array([0,0,0,0,0,1,1,0,0,0,0,0,0,0,1,1])

    no_pred = np.array([0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0])
    
    overlap_0 = np.array([1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0])

    intersection1 = (square_middle * overlap_50).sum()
    print(f"intersection: {intersection1}")
    dice1 = (2. * intersection1 + 1e-6) / (square_middle.sum() + overlap_50.sum() + 1e-6)
    print(f"Dice score: {dice1}")

    tp = np.sum(np.logical_and(square_middle == 1, overlap_50 == 1))
    tn = np.sum(np.logical_and(square_middle == 0, overlap_50 == 0))
    
    
    print(tp, tn)

    intersection2 = (square_middle * no_pred).sum()
    print(f"Intersection: {intersection2}")
    dice2 = (2. * intersection2 + 1e-6) / (square_middle.sum() + no_pred.sum() + 1e-6)
    print(f"Dice score: {dice2}")

    intersection3 = (square_middle * overlap_0).sum()
    print(f"Intersection: {intersection3}")
    dice3 = (2. * intersection3 + 1e-6) / (square_middle.sum() + overlap_0.sum() + 1e-6)
    print(f"Dice score: {dice3}")

